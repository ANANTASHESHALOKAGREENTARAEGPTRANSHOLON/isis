= Overview
:Notice: Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at. http://www.apache.org/licenses/LICENSE-2.0 . Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR  CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
:_basedir: ../
:_imagesdir: images/


== Unit tests vs Integ tests

We divide automated tests into two broad categories:

- unit tests exercise a single unit (usually a method) of a domain object, in isolation.  +
+
Dependencies of that object are mocked out.  These are written by a developer and for a developer; they are to ensure that a particular "cog in the machine" works correctly

- integration tests exercise the application as a whole, usually focusing on one particular business operation (action).  +
+
These are tests that represent the acceptance criteria of some business story; their intent should make sense to the domain expert (even if the domain expert is "non-technical")

To put it another way: integration tests are to ensure that you are *_building the right system_*, while unit tests help ensure that you are *_building the system right_*.

[TIP]
====
Isis provides autowiring dependency injection into every domain object.  This is most useful when writing unit tests; simply mock out the service and inject into the domain object.
====




== Integ tests vs BDD Specs

We further sub-divide integration tests into:

* those that are implemented in Java and JUnit (we call these simply _"integration tests"_) +
+
Even if a domain expert understands the intent of these tests, the actual implementation will be opaque to them.  Also, the only output from the tests is a (hopefully) green CI job

* tests (or rather, specifications) that are implemented in a BDD language such as link:https://cucumber.io/[Cucumber] (we call these _"BDD specs"_) +
+
The natural language specification then maps down onto some glue code that is used to drive the application.  But the benefits of taking a BDD approach include the fact that your domain expert will be able to read the tests/specifications, and that when you run the specs, you also get documentation of the application's behaviour ("living documentation").

It's up to you whether you use BDD specs for your apps; it will depend on your development process and company culture.  But you if don't then you certainly should write integration tests: acceptance criteria for user stories should be automated!





== Simulated UI (`WrapperFactory`)

When we talk about integration tests/specs here, we mean tests that exercise the domain object logic, through to the actual database.  But we also want the tests to exercise the app from the users's perspective, which means including the user interface.

For most other frameworks that would require having to test the application in a very heavy weight/fragile fashion using a tool such as link:http://seleniumhq.org[Selenium], driving a web browser to navigate .  In this regard though, Isis has a significant trick up its sleeve.  Because Isis implements the naked objects pattern, it means that the UI is generated automatically from the UI.  This therefore allows for other implementations of the UI.

The <<_wrapper_factory, `WrapperFactory`>> domain service allows a test to wrap domain objects and thus to interact with said objects "as if" through the UI:

image::{_imagesdir}testing/integ-tests.png[width="700px"]

If the test invokes an action that is disabled, then the wrapper will throw an appropriate exception.  If the action is ok to invoke, it delegates through.

What this means is that an Isis application can be tested end-to-end without having to deploy it onto a webserver; the whole app can be tested while running in-memory.  Although integration tests re (necessarily) slower than unit tests, they are not any harder to write (in fact, in some respects they are easier).





== Given/When/Then

Whatever type of test/spec you are writing, we recommend you follow the given/when/then idiom:

* *given* the system is in this state (preconditions)
* *when* I poke it with a stick
* *then* it looks like this (postconditions)

For unit tests with a mocking library (we tend to use link:http://jmock.org[JMock] but others are also fine) it can be worth considering four steps:

* *given* the system is in this state
* *expecting* these interactions (set up the mock expectations here)
* *when* I poke it with a stick
* *then* these interactions should have occurred.

[TIP]
.Distinguish between queries vs mutators
====
For mock interactions that simply retrieve some data, your test should not need to verify that it occurred.  If the system were to be refactored and starts caching some data, you don't really want your tests to start breaking because they are no longer performing a query that once they did.  If using JMock API this means using the `allowing(..)` method to set up the expectation.

On the other hand mocks that mutate the state of the system you probably should assert have occurred.  If using JMock this typically means using the `oneOf(...)` method.
====


A good test should be 5 to 10 lines long; the test should be there to help you reason about the behaviour of the system.  Certainly if the test becomes more than 20 lines it'll be too difficult to understand.

The "when" part is usually a one-liner, and in the "then" part there will often be only two or three assertions that you want to make that the system has changed as it should.

For unit test the "given" part shouldn't be too difficult either: just instantiate the class under test, wire in the appropriate mocks and set up the expectations.  And if there are too many mock expectations to set up, then "listen to the tests" ... they are telling you your design needs some work.

Where things get difficult though is the "given" for integration tests; which is the topic of the next section...




== Fixture Management

In the previous section we discussed using given/when/then as a form of organizing tests, and why you should keep your tests small.

For integration tests though it can be difficult to keep the "given" short; there could be a lot of prerequisite data that needs to exist before you can actually exercise your system.  Moreover, however we do set up that data, but we also want to do so in a way that is resilient to the system changing over time.

On a very simple system you could probably get away with using SQL to insert directly into the database, or you could use a toolkit such as link:http://dbunit.sourceforge.net/howto.html[dbunit] to upload data from flat files.  Such approaches aren't particularly maintainable though.  If in the future the domain entities (and therefore corresponding database tables) change their structure, then all of those data sets will need updating.

Even more significantly, there's no way to guarantee that the data that's being loaded is logically consistent with the business behaviour of the domain objects themselves.  That is, there's nothing to stop your test from putting data into the database that would be invalid if one attempted to add it through the app.

The solution that Isis provides is a small library called *_fixture scripts_*.  A fixture script is basically a wrapper for executing arbitrary work, but that work almost always invoking a business action.  These fixture scripts can then be organized either in a fairly flat structure (eg as in the http://github.com/isisaddons/isis-app-todoapp}[Isis addons' todoapp], or as a composite pattern (eg as in https://github.com/estatio/estatio/blob/ea20a6ce257acede50de6ce4fd2ff29713fcd689/estatioapp/fixture/src/main/java/org/estatio/fixture/invoice/InvoiceForLeaseItemTypeOfDiscountOneQuarterForOxfMiracle005.java#L66)[Estatio open source app].

[TIP]
====
If you want to learn more on this topic (with live coding!), check out this https://skillsmatter.com/skillscasts/5638-to-those-whom-much-is-given-much-is-expected[presentation] given at BDD Exchange 2014.
====




== Fake data

In any given test there are often quite a few variables involved, to initialize the state of the objects, or to act as arguments for invoking a method, or when asserting on post-conditions.  Sometimes those values are important (eg verifying that an `Order`'s state went from PENDING to SHIPPED, say), but often they aren't (a customer's name, for example) but nevertheless need to be set up (especially in integration tests).

We want our tests to be easily understood, and we want the reader's eye to be drawn to the values that are significant and ignore those that are not.

One way to do this is to use random (or fake) values for any insignificant data.  This in effect tells the reader that "any value will do".  Moreover, if it turns out that any data won't do, and that there's some behaviour that is sensitive to the value, then the test will start to flicker, passing and then failing depending on inputs.  This is A Good Thing&#8482;.

Apache Isis does not, itself, ship with a fake data library.  However, the http://github.com/isisaddons/isis-module-fakedata}[Isis addons' fakedata] module (non-ASF) does provide exactly this capability.

[TIP]
====
Using fake data works very well with fixture scripts; the fixture script can invoke the business action with sensible (fake/random) defaults, and only require that the essential information is passed into it by the test.
====


With all that said, let's look in detail at the testing features provided by Apache Isis.


